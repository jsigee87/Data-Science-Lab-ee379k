{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "## Problem 8 from Chapter 5\n",
    "\n",
    "We will now perform cross-validation on a simulated data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A\n",
    "Generate a simulated data set as follows:\n",
    "```\n",
    "set.seed(1)\n",
    "x=rnorm(100)\n",
    "y=x-2*x^2+rnorm (100)\n",
    "```\n",
    "In this data set, what is n and what is p? Write out the model\n",
    "used to generate the data in equation form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "x = np.random.randn(100)\n",
    "y = (x-(2*(x*x)) + np.random.randn(100))\n",
    "B0 = np.ones(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N is number of samples and in this case it is 100. P is number of predictors and equal to 1 in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6bac2dec88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## creating a scatter plto\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111)\n",
    "_ = ax.scatter(x, y, alpha=0.7, s=50, color = ['red','blue'], marker= '.')\n",
    "_ = plt.title('Scatter of 2 Sample Distributions', FontSize=12)\n",
    "#_ = plt.legend(loc=, prop={'size' : 12})\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B\n",
    "Create a scatterplot of X against Y . Comment on what you find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X and Y are highly correlated. y is simply shift of x with added gaussian noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C\n",
    "Set a random seed, and then compute the LOOCV errors that\n",
    "result from fitting the following four models using least squares:<br>\n",
    "$i. Y = \\beta_0 + \\beta_1 X $<br>\n",
    "$ii. Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2$<br>\n",
    "$iii. Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3$<br>\n",
    "$iv. Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\beta_4 X^4$<br>\n",
    "Note you may find it helpful to use the data.frame() function\n",
    "to create a single data set containing both X and Y ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting leave one out and linear regression model\n",
    "loo = LeaveOneOut()\n",
    "clf = LinearRegression()\n",
    "\n",
    "# Creating copies of the original data for local use\n",
    "x_copy =x\n",
    "y_copy =y\n",
    "\n",
    "# Creating arrays with power 2,3,4 of x to use in models 2,3,4\n",
    "x_2 = np.power(x_copy, 2)\n",
    "x_3 = np.power(x_copy, 3)\n",
    "x_4 = np.power(x_copy, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benerating a data frame from generated data\n",
    "# creating dictionary to generate data frame\n",
    "# B0 is simply a column of ones\n",
    "dict_data = {'B0':B0,\n",
    "        'x':x_copy,     \n",
    "       'y':y_copy}\n",
    "dataset_1 = pd.DataFrame(dict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the scores with 1 degrees of freedom is 11.14681456827608\n"
     ]
    }
   ],
   "source": [
    "# This function takes in test and train indexes,splits data into train and test,\n",
    "# and calculates mean squared error and appends it to score\n",
    "scores_1 = []\n",
    "def calc_mse_1(train_index, test_index):\n",
    "    train = dataset_1.loc[train_index]\n",
    "    test = dataset_1.loc[test_index]\n",
    "    X_train = train[['B0','x']]#.values.reshape(-1,1)\n",
    "    y_train = train['y']\n",
    "    X_test = test[['B0','x']]#.values.reshape(-1,1)\n",
    "    y_test = test['y']\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    error = mse(pred,y_test)\n",
    "    scores_1.append(error)\n",
    "    \n",
    "# Splits data set into train and test leaving one out and repeats n times\n",
    "for train_index, test_index in loo.split(dataset_1):\n",
    "    calc_mse_1(train_index, test_index)\n",
    "\n",
    "scores_1 = np.asarray(scores_1)\n",
    "mean_1 = np.mean(scores_1)\n",
    "\n",
    "print(\"Mean of the scores with 1 degrees of freedom is {}\".format(mean_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.205\n",
      "Model:                            OLS   Adj. R-squared:                  0.197\n",
      "Method:                 Least Squares   F-statistic:                     25.29\n",
      "Date:                Mon, 26 Feb 2018   Prob (F-statistic):           2.23e-06\n",
      "Time:                        14:02:12   Log-Likelihood:                -255.99\n",
      "No. Observations:                 100   AIC:                             516.0\n",
      "Df Residuals:                      98   BIC:                             521.2\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "B0            -2.0823      0.317     -6.566      0.000      -2.712      -1.453\n",
      "x              1.5805      0.314      5.029      0.000       0.957       2.204\n",
      "==============================================================================\n",
      "Omnibus:                       68.899   Durbin-Watson:                   2.095\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              359.135\n",
      "Skew:                          -2.287   Prob(JB):                     1.03e-78\n",
      "Kurtosis:                      11.079   Cond. No.                         1.08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "## split dataset into y and X and compute statistical significance of the coefs using statsmodel\n",
    "\n",
    "X_1 = dataset_1[['B0','x']]\n",
    "y_1 = dataset_1['y']\n",
    "\n",
    "\n",
    "model_1 = sm.OLS(y_1, X_1)\n",
    "results_1 = model_1.fit()\n",
    "print(results_1.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part ii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary to generate data frame\n",
    "# B0 is simply a column of ones\n",
    "dict_data = {'B0':B0,\n",
    "             'x':x_copy,\n",
    "            'x^2':x_2,\n",
    "             'y':y_copy}\n",
    "dataset_2 = pd.DataFrame(dict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the scores with 2 degrees of freedom is 1.0678843695488707\n"
     ]
    }
   ],
   "source": [
    "# This function takes in test and train indexes,splits data into train and test,\n",
    "# and calculates mean squared error and appends it to score\n",
    "scores_2 = []\n",
    "def calc_mse_2(train_index, test_index):\n",
    "    train = dataset_2.loc[train_index]\n",
    "    test = dataset_2.loc[test_index]\n",
    "    X_train = train[['B0','x','x^2']]\n",
    "    y_train = train['y']\n",
    "    X_test = test[['B0','x','x^2']]\n",
    "    y_test = test['y']\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    error = mse(pred,y_test)\n",
    "    scores_2.append(error)\n",
    "    \n",
    "# Splits data set into train and test leaving one out and repeats n times\n",
    "for train_index, test_index in loo.split(dataset_2):\n",
    "    calc_mse_2(train_index, test_index)\n",
    "\n",
    "scores_2 = np.asarray(scores_2)\n",
    "mean_2 = np.mean(scores_2)\n",
    "\n",
    "print(\"Mean of the scores with 2 degrees of freedom is {}\".format(mean_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.921\n",
      "Model:                            OLS   Adj. R-squared:                  0.919\n",
      "Method:                 Least Squares   F-statistic:                     564.8\n",
      "Date:                Mon, 26 Feb 2018   Prob (F-statistic):           3.60e-54\n",
      "Time:                        14:02:13   Log-Likelihood:                -140.61\n",
      "No. Observations:                 100   AIC:                             287.2\n",
      "Df Residuals:                      97   BIC:                             295.0\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "B0             0.0424      0.123      0.344      0.732      -0.203       0.288\n",
      "x              1.0181      0.101     10.037      0.000       0.817       1.219\n",
      "x^2           -2.0428      0.069    -29.631      0.000      -2.180      -1.906\n",
      "==============================================================================\n",
      "Omnibus:                        1.154   Durbin-Watson:                   2.122\n",
      "Prob(Omnibus):                  0.561   Jarque-Bera (JB):                1.115\n",
      "Skew:                          -0.250   Prob(JB):                        0.573\n",
      "Kurtosis:                       2.870   Cond. No.                         2.55\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "## split dataset into y and X and compute statistical significance of the coefs using statsmodel\n",
    "X_2 = dataset_2[['B0','x','x^2']]\n",
    "y_2 = dataset_2['y']\n",
    "\n",
    "\n",
    "model_2 = sm.OLS(y_2, X_2)\n",
    "results_2 = model_2.fit()\n",
    "print(results_2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part iii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary to generate data fram\n",
    "# B0 is simply a column of ones\n",
    "dict_data = {'B0':B0,\n",
    "             'x':x_copy,\n",
    "             'x^2':x_2,\n",
    "             'x^3':x_3,\n",
    "             'y':y_copy}\n",
    "dataset_3 = pd.DataFrame(dict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the scores with 3 degrees of freedom is 0.9965573529301355\n"
     ]
    }
   ],
   "source": [
    "# This function takes in test and train indexes,splits data into train and test,\n",
    "# and calculates mean squared error and appends it to score\n",
    "scores_3 = []\n",
    "def calc_mse_3(train_index, test_index):\n",
    "    train = dataset_3.loc[train_index]\n",
    "    test = dataset_3.loc[test_index]\n",
    "    X_train = train[['B0','x','x^2','x^3']]\n",
    "    y_train = train['y']\n",
    "    X_test = test[['B0','x','x^2','x^3']]\n",
    "    y_test = test['y']\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    error = mse(pred,y_test)\n",
    "    scores_3.append(error)\n",
    "    \n",
    "# Splits data set into train and test leaving one out and repeats n times\n",
    "for train_index, test_index in loo.split(dataset_3):\n",
    "    calc_mse_3(train_index, test_index)\n",
    "\n",
    "scores_3 = np.asarray(scores_3)\n",
    "mean_3 = np.mean(scores_3)\n",
    "\n",
    "print(\"Mean of the scores with 3 degrees of freedom is {}\".format(mean_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.925\n",
      "Model:                            OLS   Adj. R-squared:                  0.922\n",
      "Method:                 Least Squares   F-statistic:                     392.9\n",
      "Date:                Mon, 26 Feb 2018   Prob (F-statistic):           9.35e-54\n",
      "Time:                        14:02:13   Log-Likelihood:                -138.17\n",
      "No. Observations:                 100   AIC:                             284.3\n",
      "Df Residuals:                      96   BIC:                             294.8\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "B0             0.1219      0.126      0.964      0.338      -0.129       0.373\n",
      "x              1.2780      0.155      8.251      0.000       0.971       1.585\n",
      "x^2           -2.1587      0.086    -25.135      0.000      -2.329      -1.988\n",
      "x^3           -0.0911      0.042     -2.190      0.031      -0.174      -0.009\n",
      "==============================================================================\n",
      "Omnibus:                        0.817   Durbin-Watson:                   2.182\n",
      "Prob(Omnibus):                  0.665   Jarque-Bera (JB):                0.731\n",
      "Skew:                          -0.206   Prob(JB):                        0.694\n",
      "Kurtosis:                       2.929   Cond. No.                         7.79\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "## split dataset into y and X and compute statistical significance of the coefs using statsmodel\n",
    "X_3 = dataset_3[['B0','x','x^2','x^3']]\n",
    "y_3 = dataset_3['y']\n",
    "\n",
    "\n",
    "model_3 = sm.OLS(y_3, X_3)\n",
    "results_3 = model_3.fit()\n",
    "print(results_3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part iv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary to generate data fram\n",
    "dict_data = {'B0':B0,\n",
    "             'x':x_copy,\n",
    "             'x^2':x_2,\n",
    "             'x^3':x_3,\n",
    "             'x^4':x_4,\n",
    "             'y':y_copy}\n",
    "dataset_4 = pd.DataFrame(dict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the scores with 4 degrees of freedom is 1.1941575019349997\n"
     ]
    }
   ],
   "source": [
    "## this function takes in test and train indexes,splits data into train and test,\n",
    "## and calculates mean squared error and appends it to score\n",
    "scores_4 = []\n",
    "def calc_mse_4(train_index, test_index):\n",
    "    train = dataset_4.loc[train_index]\n",
    "    test = dataset_4.loc[test_index]\n",
    "    X_train = train[['B0','x','x^2','x^3','x^4']]\n",
    "    y_train = train['y']\n",
    "    X_test = test[['B0','x','x^2','x^3','x^4']]\n",
    "    y_test = test['y']\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    error = mse(pred,y_test)\n",
    "    scores_4.append(error)\n",
    "    \n",
    "## splits data set into train and test leaving one out and repeats n times\n",
    "for train_index, test_index in loo.split(dataset_4):\n",
    "    calc_mse_4(train_index, test_index)\n",
    "\n",
    "scores_4 = np.asarray(scores_4)\n",
    "mean_4 = np.mean(scores_4)\n",
    "\n",
    "print(\"Mean of the scores with 4 degrees of freedom is {}\".format(mean_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.925\n",
      "Model:                            OLS   Adj. R-squared:                  0.922\n",
      "Method:                 Least Squares   F-statistic:                     291.7\n",
      "Date:                Mon, 26 Feb 2018   Prob (F-statistic):           2.00e-52\n",
      "Time:                        14:02:13   Log-Likelihood:                -138.16\n",
      "No. Observations:                 100   AIC:                             286.3\n",
      "Df Residuals:                      95   BIC:                             299.3\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "B0             0.1321      0.143      0.922      0.359      -0.152       0.416\n",
      "x              1.2595      0.196      6.418      0.000       0.870       1.649\n",
      "x^2           -2.1809      0.167    -13.039      0.000      -2.513      -1.849\n",
      "x^3           -0.0811      0.077     -1.056      0.293      -0.234       0.071\n",
      "x^4            0.0049      0.032      0.155      0.877      -0.058       0.068\n",
      "==============================================================================\n",
      "Omnibus:                        0.840   Durbin-Watson:                   2.179\n",
      "Prob(Omnibus):                  0.657   Jarque-Bera (JB):                0.744\n",
      "Skew:                          -0.209   Prob(JB):                        0.689\n",
      "Kurtosis:                       2.936   Cond. No.                         32.6\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "## split dataset into y and X and compute statistical significance of the coefs using statsmodel\n",
    "X_4 = dataset_4[['B0','x','x^2','x^3','x^4']]\n",
    "y_4 = dataset_4['y']\n",
    "\n",
    "\n",
    "model_4 = sm.OLS(y_4, X_4)\n",
    "results_4 = model_4.fit()\n",
    "print(results_4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D\n",
    "Repeat (c) using another random seed, and report your results.\n",
    "Are your results the same as what you got in (c)? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a new distribution with a random seed\n",
    "# _n after a variable name refers to coming from this new distribution\n",
    "\n",
    "random.seed(np.random.randint(10,100))\n",
    "x_n = np.random.randn(100)\n",
    "y_n = (x_n-(2*(x_n*x_n)) + np.random.randn(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating copies of the original data for local use\n",
    "x_copy_n = x_n\n",
    "y_copy_n = y_n\n",
    "\n",
    "# Creating arrays with power 2,3,4 of x to use in models 2,3,4\n",
    "x_2_n = np.power(x_copy_n, 2)\n",
    "x_3_n = np.power(x_copy_n, 3)\n",
    "x_4_n = np.power(x_copy_n, 4)\n",
    "\n",
    "# using same loo and linearregression model obtained in part c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a data frame from generated data\n",
    "# creating dictionary to generate data frame\n",
    "dict_data = {'B0':B0,\n",
    "             'x':x_copy_n,\n",
    "            'y':y_copy_n}\n",
    "dataset_1_n = pd.DataFrame(dict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the scores with 1 degrees of freedom is 16.41644155680011\n"
     ]
    }
   ],
   "source": [
    "## This function takes in test and train indexes,splits data into train and test,\n",
    "## and calculates mean squared error and appends it to score\n",
    "scores_1_n = []\n",
    "def calc_mse_1_n(train_index, test_index):\n",
    "    train = dataset_1_n.loc[train_index]\n",
    "    test = dataset_1_n.loc[test_index]\n",
    "    X_train = train[['B0','x']]\n",
    "    y_train = train['y']\n",
    "    X_test = test[['B0','x']]\n",
    "    y_test = test['y']\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    error = mse(pred,y_test)\n",
    "    scores_1_n.append(error)\n",
    "    \n",
    "## splits data set into train and test leaving one out and repeats n times\n",
    "for train_index, test_index in loo.split(dataset_1_n):\n",
    "    calc_mse_1_n(train_index, test_index)\n",
    "\n",
    "scores_1_n = np.asarray(scores_1_n)\n",
    "mean_1_n = np.mean(scores_1_n)\n",
    "\n",
    "print(\"Mean of the scores with 1 degrees of freedom is {}\".format(mean_1_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part ii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary to generate data frame\n",
    "dict_data = {'B0':B0,\n",
    "             'x':x_copy_n,\n",
    "             'x^2':x_2_n,\n",
    "             'y':y_copy_n}\n",
    "dataset_2_n = pd.DataFrame(dict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the scores with 2 degrees of freedom is 0.7726639051864902\n"
     ]
    }
   ],
   "source": [
    "# This function takes in test and train indexes,splits data into train and test,\n",
    "# and calculates mean squared error and appends it to score\n",
    "scores_2_n = []\n",
    "def calc_mse_2_n(train_index, test_index):\n",
    "    train = dataset_2_n.loc[train_index]\n",
    "    test = dataset_2_n.loc[test_index]\n",
    "    X_train = train[['B0','x','x^2']]\n",
    "    y_train = train['y']\n",
    "    X_test = test[['B0','x','x^2']]\n",
    "    y_test = test['y']\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    error = mse(pred,y_test)\n",
    "    scores_2_n.append(error)\n",
    "    \n",
    "## Splits data set into train and test leaving one out and repeats n times\n",
    "for train_index, test_index in loo.split(dataset_2_n):\n",
    "    calc_mse_2_n(train_index, test_index)\n",
    "\n",
    "scores_2_n = np.asarray(scores_2_n)\n",
    "mean_2_n = np.mean(scores_2_n)\n",
    "\n",
    "print(\"Mean of the scores with 2 degrees of freedom is {}\".format(mean_2_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part iii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary to generate data fram\n",
    "dict_data = {'B0':B0,\n",
    "             'x':x_copy_n,\n",
    "             'x^2':x_2_n,\n",
    "             'x^3':x_3_n,\n",
    "             'y':y_copy_n}\n",
    "dataset_3_n = pd.DataFrame(dict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the scores with 3 degrees of freedom is 0.7596657376816897\n"
     ]
    }
   ],
   "source": [
    "# This function takes in test and train indexes,splits data into train and test,\n",
    "# and calculates mean squared error and appends it to score\n",
    "scores_3_n = []\n",
    "def calc_mse_3_n(train_index, test_index):\n",
    "    train = dataset_3_n.loc[train_index]\n",
    "    test = dataset_3_n.loc[test_index]\n",
    "    X_train = train[['B0','x','x^2','x^3']]\n",
    "    y_train = train['y']\n",
    "    X_test = test[['B0','x','x^2','x^3']]\n",
    "    y_test = test['y']\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    error = mse(pred,y_test)\n",
    "    scores_3_n.append(error)\n",
    "    \n",
    "# Splits data set into train and test leaving one out and repeats n times\n",
    "for train_index, test_index in loo.split(dataset_3_n):\n",
    "    calc_mse_3_n(train_index, test_index)\n",
    "\n",
    "scores_3_n = np.asarray(scores_3_n)\n",
    "mean_3_n = np.mean(scores_3_n)\n",
    "\n",
    "print(\"Mean of the scores with 3 degrees of freedom is {}\".format(mean_3_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part iv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary to generate data fram\n",
    "dict_data = {'B0':B0,\n",
    "             'x':x_copy_n,\n",
    "             'x^2':x_2_n,\n",
    "             'x^3':x_3_n,\n",
    "             'x^4':x_4_n,\n",
    "             'y':y_copy_n}\n",
    "dataset_4_n = pd.DataFrame(dict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the scores with 4 degrees of freedom is 0.7839156641370338\n"
     ]
    }
   ],
   "source": [
    "# This function takes in test and train indexes,splits data into train and test,\n",
    "# and calculates mean squared error and appends it to score\n",
    "scores_4_n = []\n",
    "def calc_mse_4_n(train_index, test_index):\n",
    "    train = dataset_4_n.loc[train_index]\n",
    "    test = dataset_4_n.loc[test_index]\n",
    "    X_train = train[['B0','x','x^2','x^3','x^4']]\n",
    "    y_train = train['y']\n",
    "    X_test = test[['B0','x','x^2','x^3','x^4']]\n",
    "    y_test = test['y']\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    error = mse(pred,y_test)\n",
    "    scores_4_n.append(error)\n",
    "    \n",
    "# Splits data set into train and test leaving one out and repeats n times\n",
    "for train_index, test_index in loo.split(dataset_4_n):\n",
    "    calc_mse_4_n(train_index, test_index)\n",
    "\n",
    "scores_4_n = np.asarray(scores_4_n)\n",
    "mean_4_n = np.mean(scores_4_n)\n",
    "\n",
    "print(\"Mean of the scores with 4 degrees of freedom is {}\".format(mean_4_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part E\n",
    "Which of the models in (c) had the smallest LOOCV error? Is\n",
    "this what you expected? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2nd model has the smallest mean squared error. This is expected because our data can be modelled best in 2 variables as we can see from the scatter plot. 3 and 4 degrees of freedom result in overfitting which increases our mean error a little."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part F\n",
    "Comment on the statistical significance of the coefficient estimates\n",
    "that results from fitting each of the models in (c) using\n",
    "least squares. Do these results agree with the conclusions drawn\n",
    "based on the cross-validation results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our data can be best fit in two variables, we can see it from the scatter plot. We find that coefficients B1 and B2 are the most statistically significant. Also, we can see from our results that B3 and B4 might overfit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
